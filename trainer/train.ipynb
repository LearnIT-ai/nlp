{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"google/flan-t5-xl\"\n",
    "SMALLE_MODEL_PATH = \"google/flan-t5-base\" # FOR FIRST TRAIN THIS MODEL BECAUSE WE DONT HAVE RESOURSES TO TUNING LARGER MODEL\n",
    "DATA_PATH = \"data/gec-only\"\n",
    "DEVICE = \"cuda\"\n",
    "MAX_LENGTH = 128\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(split, tokenized=False):\n",
    "    subfolder = \"source-sentences-tokenized\" if tokenized else \"source-sentences\"\n",
    "    source_path = os.path.normpath(os.path.join(DATA_PATH, split, subfolder))\n",
    "\n",
    "    subfolder = \"target-sentences-tokenized\" if tokenized else \"target-sentences\"\n",
    "    target_path = os.path.normpath(os.path.join(DATA_PATH, split, subfolder))\n",
    "\n",
    "    if not os.path.exists(source_path) or not os.path.exists(target_path):\n",
    "        raise FileNotFoundError(f\"Path {source_path} or {target_path} not found. Check the structure of project and DATA_PATH.\")\n",
    "\n",
    "    source_files = sorted([os.path.join(source_path, f) for f in os.listdir(source_path) if f.endswith(\".txt\")])\n",
    "    target_files = sorted([os.path.join(target_path, f) for f in os.listdir(target_path) if f.endswith(\".txt\")])\n",
    "\n",
    "    data = []\n",
    "    for src_file, tgt_file in zip(source_files, target_files):\n",
    "        with open(src_file, \"r\", encoding=\"utf-8\") as src, open(tgt_file, \"r\", encoding=\"utf-8\") as tgt:\n",
    "            source_sentences = [line.strip() for line in src.readlines()]\n",
    "            target_sentences = [line.strip() for line in tgt.readlines()]\n",
    "            data.extend(zip(source_sentences, target_sentences))\n",
    "\n",
    "    return pd.DataFrame(data, columns=[\"source\", \"target\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  source  \\\n",
      "0      Byte for France –∞–±–æ ‚Äú–ú—ñ–π –¥–æ—Å–≤—ñ–¥ –≤–µ–¥–µ–Ω–Ω—è –±–ª–æ–≥—É ...   \n",
      "1      –û—Å—Ç–∞–Ω–Ω—ñ 3 –º—ñ—Å—è—Ü—ñ –º–æ–≥–æ –∂–∏—Ç—Ç—è –≤–∏–¥–∞–ª–∏—Å—è –∞–∂ –∑–∞–Ω–∞–¥—Ç...   \n",
      "2      –°—å–æ–≥–æ–¥–Ω—ñ —Ä–æ–∑–ø–æ–≤—ñ–º –ø—Ä–æ —Ç–µ —è–∫ —ñ –Ω–∞–≤—ñ—â–æ –º–µ–Ω–µ –∑–∞–Ω–µ...   \n",
      "3      –Ø–∫—â–æ —Ü—ñ–∫–∞–≤–æ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –≤—ñ–¥—Ä–∞–∑—É –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —Ç...   \n",
      "4                                  –ú–æ—î –±–∞—á–µ–Ω–Ω—è Instagram   \n",
      "...                                                  ...   \n",
      "17124  –Ø–∫—â–æ —î –º–æ–∂–ª–∏–≤—ñ—Å—Ç—å –∑—Ä–æ–±–∏—Ç–∏ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ, –ª—é–¥–∏ –∑—Ä...   \n",
      "17125  –û—Å–æ–±–ª–∏–≤–æ, —è–∫—â–æ —ñ–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≤–æ–∫—É—î —Ç–∞–∫–µ —Ä–æ–±–∏—Ç–∏...   \n",
      "17126                   –Ø–∫–∏–º –±–æ–∫–æ–º –º–æ—Å–∫–æ–≤–∏—Ç–∏  –Ω–∞–º –±—Ä–∞—Ç–∏?   \n",
      "17127       –Ü –Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –±—Ä–∞—Ç–∏, —Ç–æ –ê–≤–µ–ª—å —Ç–µ–∂ –º–∞–≤ –±—Ä–∞—Ç–∞.   \n",
      "17128  –Ø–∫—â–æ —Å—É–¥–∏—Ç–∏ –ø–æ –∞–≤—Ç—ñ–≤—Ü—ñ, —Ç–æ –¥–µ –ü–∞–ø–∞, –∞ –¥–µ —è–∫–∏–π—Å...   \n",
      "\n",
      "                                                  target  \n",
      "0      Byte for France –∞–±–æ ‚Äú–ú—ñ–π –¥–æ—Å–≤—ñ–¥ –≤–µ–¥–µ–Ω–Ω—è –±–ª–æ–≥—É ...  \n",
      "1      –û—Å—Ç–∞–Ω–Ω—ñ 3 –º—ñ—Å—è—Ü—ñ –º–æ–≥–æ –∂–∏—Ç—Ç—è –≤–∏–¥–∞–ª–∏—Å—è –∞–∂ –∑–∞–Ω–∞–¥—Ç...  \n",
      "2      –°—å–æ–≥–æ–¥–Ω—ñ —Ä–æ–∑–ø–æ–≤—ñ–º –ø—Ä–æ —Ç–µ, —è–∫ —ñ –Ω–∞–≤—ñ—â–æ –º–µ–Ω–µ –∑–∞–Ω...  \n",
      "3      –Ø–∫—â–æ —Ü—ñ–∫–∞–≤–æ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –≤—ñ–¥—Ä–∞–∑—É –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç, —Ç...  \n",
      "4                                  –ú–æ—î –±–∞—á–µ–Ω–Ω—è Instagram  \n",
      "...                                                  ...  \n",
      "17124  –õ—ñ–∫–∞—Ä—ñ, –∫–æ–ª–∏ —Ö–æ—á—É—Ç—å –∑–¥–∞–≤–∞—Ç–∏—Å—è —Ä–æ–∑—É–º–Ω–∏–º–∏ —ñ –∫—Ä–∞—Å...  \n",
      "17125  –®–µ–ª–µ—Å—Ç–æ–≤ –±—É–¥–µ –≥–æ–≤–æ—Ä–∏—Ç–∏ –Ω–µ —Ç—ñ–ª—å–∫–∏ –ª–∞—Ç–∏–Ω—Å—å–∫–æ—é, –∞...  \n",
      "17126  ‚Äî –ú—ñ–π –±—Ä–∞—Ç —Ç–µ–∂ –æ—Ñ—ñ—Ü–µ—Ä, –º–æ—Ä—è–∫, –∞–ª–µ –≤—ñ–Ω —Å—ñ–º–µ–π–Ω–∏–π...  \n",
      "17127                                                –•–∞!  \n",
      "17128  –ß–µ—Ä–µ–∑ –≥–æ–¥–∏–Ω—É –≤–æ–Ω–∞ —Å–∫–∞–∑–∞–ª–∞: \"–°—å—é–¥—ñ, —è —Å–ø–æ–¥—ñ–≤–∞—é—Å...  \n",
      "\n",
      "[17129 rows x 2 columns]\n",
      "                                                 source  \\\n",
      "0     –ù–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ä–∞–Ω–∫—É —Ä—ñ–≤–Ω–æ –æ –æ–¥–∏–Ω–∞–¥—Ü—è—Ç—ñ–π –≥–æ–¥–∏–Ω—ñ, –∫...   \n",
      "1     \"–Ø –Ω–µ —î –¥–æ–∫—Ç–æ—Ä\" - —Å–∫–∞–∑–∞–≤ —è: \"–ß–æ–º—É –≤–∞–º –Ω–µ –ø—ñ—Ç–∏ ...   \n",
      "2     \"–ë–æ—Å—Å\" - —Å–∫–∞–∑–∞–≤ –≤—ñ–Ω: \"–î–æ–∫—Ç–æ—Ä –•–æ—Å–∫—ñ–Ω—Å –º–∞—î –ø—Ä–æ—ó—Ö...   \n",
      "3     –í—ñ–Ω —î —î–¥–∏–Ω–∏–π –ª—ñ–∫–∞—Ä –≤ –º—ñ—Å—Ç—ñ —ñ –ú–∞—Å—Å–∞ –±–∞–Ω–∫–∏ —Å–∏–ª—å–Ω...   \n",
      "4     –í—ñ–Ω –≤—ñ–¥–ø—Ä–∞–≤–∏–≤ –º–µ–Ω—ñ, —â–æ–± —Å–ø–∏—Ç–∞–≤ —á–∏ –ø–æ–≥–æ–¥–∂—É–π—Ç–µ—Å—è...   \n",
      "...                                                 ...   \n",
      "1462  –ú–µ–Ω—ñ —è–∫ –ª—é–¥–∏–Ω—ñ –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω–æ –≤–∏–¥–∞–≤–∞—Ç–∏ –±–∞–∂–∞–Ω–µ –∑–∞...   \n",
      "1463  –ú–µ–Ω—ñ –Ω—ñ–∫–æ–ª–∏ –Ω–µ –≤–∏—Ö–æ–¥–∏—Ç—å —Ä–æ–±–∏—Ç–∏ –ø—ñ–∞—Ä –Ω–∞ —Ä—ñ–≤–Ω–æ–º—É...   \n",
      "1464  –ù–µ –∑–Ω–∞—é, —â–æ —Ü—å–æ–º—É –ø—Ä–∏—á–∏–Ω–∞: –≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ–π –∫—Ä–∏—Ç–∏–∫, ...   \n",
      "1465  –û–¥–Ω–∞–∫ –º–µ–Ω—ñ –Ω—É—É—É –¥—É–∂–µ —Å–∫–ª–∞–¥–Ω–æ –≥—ñ–ø–µ—Ä–±–æ–ª—ñ–∑—É–≤–∞–ª–∏ –¥...   \n",
      "1466  –û–∫—Ä—ñ–º —Ç–æ–≥–æ, —â–æ —Ü–µ –≤—Å–µ –¥–æ—Å–∏—Ç—å –≤—ñ–¥–Ω–æ—Å–Ω–æ, —Ç–æ –Ω–∞ –¥...   \n",
      "\n",
      "                                                 target  \n",
      "0     –ù–∞—Å—Ç—É–ø–Ω–æ–≥–æ —Ä–∞–Ω–∫—É —Ä—ñ–≤–Ω–æ –æ–± –æ–¥–∏–Ω–∞–¥—Ü—è—Ç—ñ–π –≥–æ–¥–∏–Ω—ñ, ...  \n",
      "1     \"–Ø –Ω–µ —î –¥–æ–∫—Ç–æ—Ä\", ‚Äî —Å–∫–∞–∑–∞–≤ —è. ‚Äî –ß–æ–º—É –≤–∞–º –Ω–µ –ø—ñ—Ç...  \n",
      "2     \"–ë–æ—Å—Å, ‚Äî —Å–∫–∞–∑–∞–≤ –≤—ñ–Ω. ‚Äî –î–æ–∫—Ç–æ—Ä –•–æ—Å–∫—ñ–Ω—Å –º–∞—î –ø—Ä–æ—ó...  \n",
      "3     –í—ñ–Ω ‚Äî —î–¥–∏–Ω–∏–π –ª—ñ–∫–∞—Ä —É –º—ñ—Å—Ç—ñ —ñ –ú–∞—Å—Å–∞ –±–∞–Ω–∫–∏ —Å–∏–ª—å–Ω...  \n",
      "4     –í—ñ–Ω –≤—ñ–¥–ø—Ä–∞–≤–∏–≤ –º–µ–Ω–µ, —â–æ–± —Å–ø–∏—Ç–∞–≤, —á–∏ –ø–æ–≥–æ–¥–∂—É—î—Ç–µ—Å...  \n",
      "...                                                 ...  \n",
      "1462  –î—Ä—É–∑—ñ, –æ—Å—å –∑–º—ñ–Ω–∏ –≤ –Ω–∞—à–∏—Ö –µ–∫—Å–∫—É—Ä—Å—ñ–π–Ω–∏—Ö –ø–ª–∞–Ω–∞—Ö: ...  \n",
      "1463  –í–∏—Ö—ñ–¥ –∑—ñ —à–∫–æ–ª–∏ –æ–± 11 –≥–æ–¥, –∑—É—Å—Ç—Ä—ñ—á –±—ñ–ª—è –°–æ—Ñ—ñ—ó–≤—Å...  \n",
      "1464        –í–∞—Ä—Ç—ñ—Å—Ç—å: 90 –≥—Ä–Ω (–ú–ö, —Ç—Ä–∞–Ω—Å–ø–æ—Ä—Ç–Ω—ñ –≤–∏—Ç—Ä–∞—Ç–∏).  \n",
      "1465  –Ü–Ω—à—ñ –ø–ª–∞–Ω–∏ (–ø–æ—ó–Ω–≥, —É–∫—Ä–∞—ó–Ω–æ–∑–Ω–∞–≤—Å—Ç–≤–æ, —ñ–Ω—Ñ–æ—Ä–º–∞—Ç–∏–∫...  \n",
      "1466                                       –î–æ –∑—É—Å—Ç—Ä—ñ—á—ñ!  \n",
      "\n",
      "[1467 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = load_data(\"train\", tokenized=False)\n",
    "test_df = load_data(\"test\", tokenized=False)\n",
    "print(train_df)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\maks4\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17129/17129 [00:04<00:00, 4056.31 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1467/1467 [00:00<00:00, 3799.01 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"source\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(SMALLE_MODEL_PATH)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df).map(\n",
    "    lambda x: {\n",
    "        \"input_ids\": tokenizer(x[\"source\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)[\"input_ids\"],\n",
    "        \"labels\": tokenizer(x[\"target\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)[\"input_ids\"]\n",
    "    }\n",
    ")\n",
    "\n",
    "valid_dataset = Dataset.from_pandas(test_df).map(\n",
    "    lambda x: {\n",
    "        \"input_ids\": tokenizer(x[\"source\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)[\"input_ids\"],\n",
    "        \"labels\": tokenizer(x[\"target\"], truncation=True, padding=\"max_length\", max_length=MAX_LENGTH)[\"input_ids\"]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = T5ForConditionalGeneration.from_pretrained(SMALLE_MODEL_PATH).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ü§ó Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"data/results_of_training\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps = 8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=1,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    fp16=True,\n",
    "    push_to_hub=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6423 [00:00<?, ?it/s]Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "  0%|          | 10/6423 [00:10<1:46:11,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.8383, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 20/6423 [00:20<1:43:31,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.0, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 30/6423 [00:30<1:43:49,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 30.3691, 'grad_norm': nan, 'learning_rate': 5e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\transformers\\trainer.py:3612\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3610\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m   3611\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3612\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3613\u001b[0m     \u001b[38;5;66;03m# Finally we need to normalize the loss for reporting\u001b[39;00m\n\u001b[0;32m   3614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m num_items_in_batch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\accelerate\\accelerator.py:2237\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[1;34m(self, loss, **kwargs)\u001b[0m\n\u001b[0;32m   2235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   2236\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 2237\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2238\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m learning_rate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_lomo_optimizer:\n\u001b[0;32m   2239\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\torch\\_tensor.py:581\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    572\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    573\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    574\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    579\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    580\u001b[0m     )\n\u001b[1;32m--> 581\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    583\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\DD\\IT_STEP\\Project_work\\envire\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    823\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    824\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 825\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    827\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    828\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    829\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
